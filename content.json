{"pages":[],"posts":[{"title":"CH2.딥러닝의 시작, 퍼셉트","text":"퍼셉트론 알고리즘 퍼셉트론은 딥러닝의 기원이 되는 알고리즘으로, 다수의 신호를 입력으로 받아 처리한 후 하나의 신호를 출력한다. – IMAGE 좀 더 구체적으로 설명하면 입력 받은 신호에 가중치를 곱해서 신호의 총합이 정해진 한계(임계값)를 넘어설 때만 1을 출력한다. 이 동작 원리를 수식으로 나타내면 아래와 같다. – IMAGE 퍼셉트론 수식위 식의 x1,x2는 입력신호, w1,w2는 가중치를 나타낸다. 그리고 계산식의 합이 임계값(θ)를 넘는 경우에만 1을 출력한다. 입력신호(x1,x2)는 우리가 결정할 수 없는, 그저 받는 값이지만, 가중치와 임계값은 조절할 수 있다. 계산식에서 가중치(w1,w2)로 입력신호의 중요도를 조절하고, 임계값으로 얼마나 쉽게 1을 출력할 것인지를 설정한다. 가중치는 높을수록 입력신호의 값이 커져 영향력이 커지게 되며 낮을수록 그 입력신호는 영향력이 작아진다. 그리고 임계값이 낮을수록 1은 쉽게 출력될 것이다. 이처럼 가중치와 임계값은 각 신호가 결과에 주는 영향력을 조절한다. 이번에는 임계값을 좌변으로 옮겨 아래와 같이 수식으로 나타낼 수 있다. 가중치와 편향임계값을 좌변으로 넘기고(b) 임계값을 더한 계산식의 합이 0이 넘는 경우에만 1을 출력한다. 항상 계산식이 0보다 크면 1을 출력하므로 이해하기 훨씬 간편하다. 우리는 이 b를 편향이라고 부른다. 논리 회로 구현하기 앞서 작성한 퍼셉트론 식으로 논리 회로를 구현해 보자. 논리 회로는 하나 이상의 논리 값이 들어오면 게이트에 따라 출력 논리 값을 반환한다. 게이트로는 AND게이트, OR게이트, XOR게이트, NAND게이트를 살펴 볼 것이다. AND 게이트아래 표는 AND논리회로의 진리표이다. 입력 값이 둘 다 1인 경우에만 1을 반환한다. – IMAGE 이 진리표를 퍼셉트론으로 표현하려면 가중치와 편향을 어떻게 설정해야 할까? 입력값을 x1, x2에 대한 가중치를 w1, w2라고 했을 때 (w1,w2,b)는 (0.5,0.5,-0.7), (1.0,1.0,-1.0)등이 될 수 있을 것이다.이처럼 가중치와 편향을 적절히 하여 AND 논리회로를 구현해보자. 12345678910import numpy as npdef AND(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0 : return 0 else: return 1 – IMAGE OR, NAND게이트 다음으로 OR, NAND게이트도 마저 구현해 본다. OR게이트는 입력값이 모두 0인 경우를 제외하고 1을 반환하고 NAND게이트는 입력값이 모두 1인 경우에 0을 반환한다. – IMAGE 1234567891011121314151617181920def OR(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.2 tmp = np.sum(w*x) + b if tmp &lt;= 0 : return 0 else: return 1OR 함수 결과def NAND(x1, x2): x = np.array([x1, x2]) w = np.array([-0.5, -0.5]) b = 0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0 : return 0 else: return 1 NAND 함수 결과XOR 논리회로는? 아래는 XOR논리회로의 진리표이다. XOR 논리회로 진리표XOR 논리회로는 x1,x2가 다른 경우에만 1을 반환한다. 마찬가지로 코드로 구현하려니 앞서 다른 논리회로와 같은 방식으로는 구현할 수가 없다. 왜 그럴까? 그래프로 살펴보자 OR논리회로 그래프 먼저 OR진리표를 그래프로 나타낸 것이다. OR그래프는 0과 1을 분리하기 위해서 1차식으로 나타낼 수 있다. AND와 NAND논리회로 역시 1차식으로 나타낼 수 있다. 직접 그려보기 바란다. 다음으로 XOR그래프를 살펴보자 XOR논리회로 그래프XOR 그래프는 0과 1을 분리하기 위해 1차식으로 구현할 수 없다. 1과 0을 분리하기 위해서는 곡선이 들어가게 된다. 정리하면 AND,OR,NAND가 선형 문제인 반면에 XOR은 비선형 문제이므로 1차식으로 문제를 해결할 수 없는 것이다. 비선형 문제 해결하기 : 다층 퍼셉트론그렇다면 퍼셉트론 식만으로 비선형 문제를 어떻게 해결해야 할까? XOR같은 비선형 문제를 해결하는 것이야 말로 퍼셉트론의 진가이다. 1차식 만으로 해결할 수 없는 비선형 문제는 층을 쌓아 해결한다. 이것을 다층 퍼셉트론이라고 부른다. 다층 퍼셉트론을 그림으로 나타내면 다음과 같다. – IMAGE 다층 퍼셉트론하나의 처리과정을 한 층이라고 부른다. 해당 퍼셉트론은 처리 과정이 2개이므로 2층 퍼셉트론이다. 그림을 설명하면 입력신호(x1,x2)에 대한 처리를 하고 처리된 신호(s1,s2)를 다시 처리하여 y를 출력한다. 기존의 1층 처리 방식과 달리 처리된 것을 다시 처리하여 출력한다. 이 방식을 XOR에 적용해보자. 먼저 XOR 방식을 해결하기 위한 처리 과정은 아래와 같다. – IMAGE 입력 신호(x1, x2)는 다른 논리회로와 같다. 다만 입력신호를 NAND로 처리한 s1과 OR로 처리한 s2(1층)를 다시 AND 신호(2층)로 처리한다. 이를 수식으로 나타내면 아래와 같다. 12345def XOR(x1, x2): s1 = NAND(x1, x2) s2 = OR(x1, x2) y = AND(s1, s2) return y XOR 함수 결과이처럼 퍼셉트론은 층을 쌓아 더 다양한 것을 표현할 수 있다.","link":"/2020/04/11/book1-1/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/04/05/hello-world/"},{"title":"CH5. 신경망 학습하기-2 (경사하강법)","text":"지난 챕터에서는 데이터를 예측하고 예측 값에 대한 손실함수 구하기를 살펴보았다. 지난 챕터 바로가기 : https://myphiloprogramming.tistory.com/22 다음 순서를 계속 진행해보자. 경사하강법으로 가중치 값 개선하기 우리는 손실 함수 값을 줄여나감으로써 최적의 매개변수를 찾는다. 손실 함수 값을 줄이는 방법으로는 경사하강법을 사용하는데, 적용하기 전에 그 방법을 이해해보자. 먼저, 손실 함수값을 좌표 위에 찍어서 현재 위치를 확인한다. 적기로는 좌표 위에 점을 찍는다고 했지만, 실제로 차원은 가중치 매개변수 개수 만큼 있기 때문에 그릴수도, 그래프의 모양을 확인할 수도 없다. 적당히 이해하기로는 x축은 가중치 매개변수 개수 만큼있고 y축은 손실함수 값이 된다. 그림으로 나타내보면 다음과 같다.(이 그림은 이해를 돕기 위할 뿐이며 실제로는 그림으로 나타낼 수도 없다.) 전체 그래프를 모르기 때문에 어디가 손실함수 값의 최솟값인지 짐작할 수 없다. 이런 상황에서 기울기를 이용해 최솟값을 찾으려는 것이 경사법이다. 기울어진 방향에 꼭 최솟값이 있는 것은 아니지만 그 방향으로 갔을 때 손실함수 값을 줄일 수 있다. 그래서 기울기를 단서로 나아갈 방향을 정하게 된다. 기울기는 아래 그림처럼 방향을 가진 벡터로 그려진다. 기울기화살표를 보면 한 곳을 향하고 있는데, 이 때 가리키는 위치가 가장 최솟값이 된다. 정리하면 현재 위치에서 기울기를 구한 후, 손실함수 값이 낮아지는 방향으로 이동한다. 경사하강법은 현 위치에서 기울어진 방향으로 일정 거리만큼이동한다. 그런 다음 이동한 곳에서 기울기를 한번 더 구하고 또 기울어진 방향으로 나아가기를 반복함으로써 최솟값을 찾아나간다. 경사하강법을 구현하면 다음과 같다. 12345678910111213141516171819202122232425def numerical_gradient(f, x): h = 1e-4 grad = np.zeros_like(x) for idx in range(x.size): tmp_val = x[idx] x[idx] = tmp_val + h fxh1 = f(x) x[idx] = tmp_val - h fxh2 = f(x) grad[idx] = (fxh1 - fxh2) / (2*h) x[idx] = tmp_val return graddef gradient_descent(f, init_x, lr=0.01, step_num=100): x = init_x for i in range(step_num): grad = numerical_gradient(f,x) x -= lr * grad return x gradient_descent함수의 파라미터를 살펴보면, f는 최적화하려는 함수, init_x는 초깃값, lr은 학습률, step_num은 반복 횟수를 의미한다. 그리고 numerical_gradient 함수는 기울기를 구한다. init_x = np.array([-3.0, 4.0])gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100) gradient_descent 함수 실행 결과gradient_descent함수를 사용하면 step_num만큼 반복하면서 찾은 최솟값의 위치를 리턴한다. 다시 말해, 손실함수가 최솟값이 되는 매개변수 값을 리턴한다. 위 예시에서는 초기 매개변수로 [-3.0, 4.0]을 넣었더니, [-6.11e-10, 8.14e-10] 결과가 반환됐다. 2,3,4 반복하며 최적값 찾기 gradient_descent 함수가 리턴한 값은 개선된 가중치 값이다. 이제 이 값을 가지고 다시 숫자 이미지를 맞춘다. 다시 배치 데이터를 뽑고 새로 갱신된 가중치 값으로 예측한 후, 새로운 손실함수 값을 또 최소화도록 경사하강법을 적용한다. 이렇게 이 과정을 반복하면서 가중치 최적값을 찾아나간다. 1번부터 5번까지에 대한 전체 코드는 다음과 같다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117class TwoLayerNet: def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01): #가중치 초기화 self.params = {} self.params['W1'] = weight_init_std * \\ np.random.randn(input_size, hidden_size) self.params['b1'] = np.zeros(hidden_size) self.params['W2'] = weight_init_std * \\ np.random.randn(hidden_size, output_size) self.params['b2'] = np.zeros(output_size) def predict(self, x): W1, W2 = self.params['W1'], self.params['W2'] b1, b2 = self.params['b1'], self.params['b2'] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, W2) + b2 y = softmax(a2) return y def loss(self, x, t): y = self.predict(x) return cross_entropy_error(y, t) def accuracy(self, x, t): y = self.predict(x) y = np.argmax(y, axis=1) t = np.argmax(t, axis=1) accuracy = np.sum(y==t) / float(x.shape[0]) return accuracy def numerical_gradient(self, x, t): loss_W = lambda W: self.loss(x,t) grads = {} grads['W1'] = numerical_gradient(loss_W, self.params['W1']) grads['b1'] = numerical_gradient(loss_W, self.params['b1']) grads['W2'] = numerical_gradient(loss_W, self.params['W2']) grads['b2'] = numerical_gradient(loss_W, self.params['b2']) return grads#미니 배치(x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, one_hot_label=True)train_loss_list = []iters_num = 10000train_size = x_train.shape[0]batch_size = 100learning_rate = 0.1network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)for i in range(iters_num): batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] grad = network.numerical_gradient(x_batch, t_batch) for key in ('W1','b1','W2','b2'): network.params[key] -= learning_rate * grad[key] loss = network.loss(x_batch, t_batch) train_loss_list.append(loss)``` 6. 테스트 데이터로 성능 테스트 해보기이로써 신경망 구현이 끝났다. 이제 테스트 데이터를 적용해서 정확도를 확인해보자.테스트 코드는 다음과 같다.``` bash(x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, one_hot_label=True)network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)iters_num = 10000train_size = x_train.shape[0]batch_size = 100learning_rate = 0.1train_loss_list = []train_acc_list = []test_acc_list = []iters_per_epoch = max(train_size / batch_size, 1)for i in range(iters_num): batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[bathc_mask] grad = network.numerical_gradient(x_bathc, t_batch) for key in ('W1','b1','W2','b2'): network.params[key] -= learning_rate * grad[key] loss = network.loss(x_batch, t_batch) train_loss_list.append(loss) if i % iter_per_epoch == 0: train_acc = network.accuracy(x_train, t_train) test_acc = network.accuracy(x_test, t_test) train_acc_list.append(train_acc) test_acc_list.append(test_acc) print(\"train acc, test acc |\" + str(train_acc) + \", \" + str(test_acc))","link":"/2020/04/11/book1-4/"},{"title":"CH3. 딥러닝의 시작2, 신경망 - 활성화 함수","text":"앞선 글에서 퍼셉트론, 가중치, 편향, 비선형, 다중퍼셉트론을 살펴보았다. 퍼셉트론 식을 구현하는 데 있어 가중치와 편향을 적절한 값으로 직접 설정했다. 그러나 층이 많아질수록 직접 설정할 수 없을 것이다. 신경망은 학습을 통해 가중치, 편향에 대한 적절한 값을 찾아준다. 신경망 신경망 네트워크신경망 네트워크는 입력층 - 은닉층 - 출력층으로 구성되는데, 은닉층의 경우 처리 과정을 확인할 수 없다. 신경망의 구조는 다층 퍼셉트론과 유사하다. 퍼셉트론에서 신경망으로 나아가 보자. 앞서 정의한 퍼셉트론 식을 다시 보자. 단층 퍼셉트론 식x1,x2는 입력신호, w1,w2는 가중치, b는 편향이다. 이 3가지를 네트워크로 나타내보자. 단층 퍼셉트론 네트워크익숙한 그림이지만 편향이 추가됐다. 이 그림은 위 퍼셉트론 식을 1b + w1x1 + w2*x2라고 풀어서 나타낸 것이다. 우리는 이 식을 새로 정의하여 아래처럼 간략화할 수 있다. 이 식을 설명하면 기존의 계산식(b+w1x1+w2x2)이 h(x) 함수를 거쳐 출력신호 y를 반환한다. 이 때, h(x)함수는 입력이 0을 넘으면 1을 반환하고 있다. h(x)함수는 활성화 함수라 부르며, 입력 신호의 총합을 처리하여 출력 값을 정하는 역할을 한다. 다시 말해, 기존의 단층 퍼셉트론 식은 입력신호의 총합을 갖고 출력신호를 반환했지만, 이제는 입력신호의 총합이 활성화 함수를 거쳐서 출력신호를 반환한다. 이렇게 활성화 함수를 추가하는 이유는 비선형성을 추가하기 위함이다. 바로 살펴보겠지만 활성화 함수들은 모두 비선형성 함수이다. 활성화 함수가 선형 함수라면 층을 깊게 하는 의미가 없어진다. 왜냐하면 복합함수로 설명될 수 있기 때문이다. f(x) * f(x) * f(x) 이런 식으로… 즉, 은닉층이 없는 네트워크가 된다. 그래서 다층 퍼셉트론에서는 활성화 함수가 필요하다. 활성화 함수를 네트워크 그림에 포함하면 아래와 같다. 입력 신호의 총합(a)은 활성화함수(h())를 거쳐 출력값(y)를 반환한다. 활성화 함수활성화 함수의 역할을 하는 함수가 여럿있는데 대표적으로는 계단함수, 시그모이드함수, ReLu함수가 있다. 이 함수가 어떻게 활성화시키는지 살펴보자. 계단 함수 계단 함수는 임계값 이전에는 출력값이 0이 었다가 임계값을 넘으면 1이 되는 함수이다. 계단 함수를 구현한 식은 아래와 같다. 여기서 임계값은 0이다. import numpy as np def step_function(x): return np.array(x&gt;0, dtype=np.int) 구현한 식을 가지고 그래프를 그려보자. 1234567import matplotlib.pylab as pltx = np.arange(-5.0, 5.0, 0.1)y = step_function(x)plt.plot(x, y)plt.ylim(-0.1, 1.1)plt.show() 계단 함수 그래프그래프와 같이 x &lt;= 0 이면, y값은 계속 0이다가, x &gt; 0 이면 y값이 1이 된다. 앞서 언급한 단층 퍼셉트론이 이 경우에 해당한다. 시그모이드 함수 시그모이드 함수는 신경망에서 자주 이용하는 활성화 함수로 수식은 다음과 같다. exp()는 지수함수를 의미한다. 시그모이드 함수시그모이드 함수는 아래와 같이 구현할 수 있다. 12def sigmoid(x): return 1/ (1+np.exp(-x)) 시그모이드 함수를 그래프로 나타내보자. 12345x = np.arange(-5.0, 5.0, 0.1)y = sigmoid(x)plt.plot(x, y)plt.ylim(-0.1, 1.1)plt.show() 시그모이드 함수 그래프계단함수처럼 이분적이지 않고 x값에 따라 y값이 계속 달라진다. ReLu 함수 ReLu 함수도 신경망에서 주로 이용하는 함수중 하나로, 입력이 0을 넘으면 입력을 그대로 출력하고 0이하이면 0을 출력한다. 수식과 그래프는 다음과 같다. 1234567def relu(x): return np.maximum(0, x)x = np.arange(-5.0, 5.0, 0.1)y = relu(x)plt.plot(x, y)plt.ylim(-0.1, 1.1)plt.show() ReLu함수 그래프출력층 활성화 함수 앞서 신경망은 입력층 - 은닉층 - 출력층으로 구성되어 있다고 언급했는데, 출력층에서의 활성화 함수는 다른 함수를 사용한다. 일반적으로신경망이 어떤 문제를 해결하느냐에 따라 다른 함수를 사용하는데, 분류 문제를 해결하는 경우 softmax함수를 사용하고 회귀에서는 항등함수를 사용한다. 항등 함수부터 살펴보자. 항등 함수(identity function) 항등 함수는 간단하다. 입력 값을 그대로 출력한다. f(x) = x 이다. 그래서 출력층에서 항등 함수를 사용하면 입력 신호가 그대로 출력 신호가 된다. 소프트맥스 함수(softmax function) 소프트맥스 함수의 식은 다음과 같다. 소프트맥스 함수소프트맥수 함수의 분자는 입력 신호 ak의 지수함수, 분모는 모든 입력 신호의 지수 함수의 합으로 구성된다. 소프트맥스 함수를 그림으로 나타내면 다음과 같은데, 소프트맥스의 출력은 모든 입력 신호로부터 화살표를 받는다. 식의 분모에서 보듯, 출력층은 모든 입력 신호에서 영향을 받기 때문이다. 출력 신호는 모든 입력신호의 영향을 받는다.","link":"/2020/04/11/book1-2/"},{"title":"CH4. 신경망 학습하기-1 (손실함수, 교차엔트로피오차)","text":"이번 챕터에서는 신경망 학습 방법에 대해 알아본다. 우리는 “5”라고 쓴 손글씨 이미지를 입력하면 컴퓨터가 “5”라고 인식하는 모델을 만들고 싶다. 이 모델을 만들기 위해서 신경망을 학습시킬 것이다. (이를 모델링이라고도 한다.) 신경망은 학습을 통해 손글씨 값을 가장 잘 인식하는 가중치와 편향의 최적값을 찾아준다. 우리는 최적값을 가지고 숫자를 얼마나 잘 맞추는지 성능을 테스트 할 것이다. 우리가 사용할 데이터는 MNIST 패키지의 손글씨 이미지이다. 이미지는 다음과 같다. 손글씨 숫자 5손글씨로 쓴 숫자 5의 이미지이다. 이미지를 넘파이 배열로 변환하여 학습시킬 것이다. 해당 이미지는 28 * 28 사이즈로, 픽셀별로 쪼개어 배열로 만든다. 회색조 이미지에서 각 픽셀은 색상에 따라 0에서 255까지의 값을 취한다. 위 이미지를 배열로 만들면 아래와 같으며 배열의 shape는 (1,784)이다. 손글씨 이미지를 배열로 변환하나의 데이터는 위의 배열과 같다. 이제 신경망 학습법을 살펴보자. (데이터 전처리는 따로 또 포스팅할 예정입니다.) 신경망 학습 절차는 아래와 같다. 우리는 이 과정을 짚어보며 신경망 학습 방법을 이해할 것이다. 훈련데이터와 시험데이터 분리 훈련데이터 중 배치 돌릴 배치 데이터 랜덤 선택 배치 데이터로 손실함수 값 구하기 경사하강법으로 가중치 값 개선하기 2,3,4 반복하며 최적값 찾기 테스트 데이터로 성능 테스트 해보기 훈련데이터와 시험데이터 분리 MNIST 패키지의 손글씨 이미지는 7만장이다. 7만장을 훈련데이터와 시험데이터로 나눠 학습과 성능 테스트를 수행할 것이다. 훈련 데이터를 사용하여 최적의 매개변수를 찾은 다음, 시험데이터로 성능 테스트를 진행한다. 이는 범용능력을 위한 것으로, 다른 데이터가 들어왔을 때도 효과적인 값을 출력하는지 테스트하기 위함이다. 만약, 학습모델이 훈련데이터는 정확히 맞추더라도 시험데이터가 들어왔을 때 엉망이라면, 이 모델은 다른 데이터에는 사용할 수 없을 것이다. 이처럼 특정데이텅에 맞춰서 만들어진 모델을 오버피팅이라고 하며, 이 문제를 방지하기 위해 훈련데이터와 시험데이터를 분리한다. 여기서는 훈련데이터 6만장, 시험데이터를 1만장으로 분리할 것이다. 데이터를 분리하는 코드는 아래와 같다. 123456789101112131415import sys, osimport numpy as nppath = \"./deep-learning-from-scratch-master\"sys.path.append(path)from dataset.mnist import load_mnist(x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, one_hot_label=True)print(\"x_train shape is: \"+ str(x_train.shape)) #훈련데이터print(\"t_train shape is: \"+ str(t_train.shape)) #훈련데이터 레이블print(\"x_test shape is: \"+ str(x_test.shape)) #시험데이터print(\"t_test shape is: \"+ str(t_test.shape)) #시험데이터 레이블 훈련데이터, 시험데이터 shape여기서 x_train과 x_test는 훈련데이터, 시험데이터이다. 한장 데이터의 shape는 (1, 784)인데, 6만장이 있으므로 (60000, 784)이다. 시험데이터는 1만장이므로 (10000,784)이다. 그리고 t_train과 t_test는 각각 훈련데이터 레이블과 시험데이터 레이블이다. 레이블은 정답표를 배열로 나타낸 것이다. 만약 특정 손글씨 숫자의 실제값이 “2”라면, 레이블은 [0,0,1,0,0,0,0,0,0,0]가 된다. 맨 앞에서부터 0,1,2 …9까지 총 10개의 정답표이며 실제 값에만 1을 표시한다. 하나의 정답 레이블의 shape는 (1,10)이며 이미지만큼 정답표가 있기 때문에 (60000,10),(10000,10)이다. 훈련데이터 중 배치 돌릴 배치 데이터 랜덤 선택 훈련 데이터 x_train은 6만개이다. 6만개 전체를 학습 한 번에 전부 사용하면 시간이 너무 오래 걸린다. 더 많은 데이터의 경우 그 시간은 더 오래 걸릴 것이다. 이런 경우 데이터 일부를 추려 전체의 근사치로 사용한다. 가령 6만개의 훈련 데이터 중에서 100개를 무작위로 뽑아 그 100개 만을 사용하여 학습하고 다시 또 100개를 추출하여 학습하는 것을 반복한다. 이러한 학습 방법을 미니 배치 학습이라고 한다. 이렇게 무작위로 추출한 데이터를 배치 데이터라고 부르겠다. 훈련 데이터에서 지정한 수의 데이터를 무작위로 골라오는 코드를 작성해 보자. 1234567train_size = x_train.shape[0]batch_size = 100batch_mask = np.random.choice(train_size, batch_size)x_batch = x_train[batch_mask]t_batch = t_train[batch_mask]print(batch_mask) 6만 개중에서 100개 랜덤 추출하기 배치 데이터로 손실함수 값 구하기 학습에 사용할 데이터 추출까지 모두 끝났다. 이제는 이 배치 데이터를 가지고 이미지 데이터의 숫자값을 예측한 후, 손실함수 값을 구할 것이다. 먼저 이미지 데이터 예측부터 살펴보자. W = np.random.randn(784,10)def predict(x): return np.dot(x, W)W는 가중치 매개변수로, 신경망의 최종목표인 가중치 최적값 찾기가 바로 이 W 변수이다. 신경망은 학습을 통해 W변수의 최적값을 찾을 것이다. 첫 예측에는 가중치 값이 없으므로 정규분포 값으로 랜덤추출하였다. 입력할 배치 데이터의 shape는 (100, 784)이므로 이미지당 예측값을 추정하기 위해서 가중치는 (784,10)형태여야 한다. 이는 행렬 곱을 위해서는 앞 행렬의 열과 뒤 행렬의 행이 같아야 하는 계산 방식 때문이다. 이렇게 하면 예측값의 shape는 (100,10)이며 이는 원소가 10개인 리스트가 100행이 있음을 의미한다. 다시 말해 predict()함수의 리턴 값의 shape는 (100,10)이 된다. 앞서 구한 배치 데이터(x_batch)를 가지고 predict 리턴 값의 한 줄을 출력해보자. predict(x_batch)[0] 추정치위 배열이 신경망이 이미지 데이터를 보고 생성한 추정치이다. 이 추정치가 100개가 있다. 추정치를 설명하면, 이미지 데이터가 0일 가능성이 14, 1일 가능성이 11, 9일 가능성이 10을 나타낸다. 그러면 최종 선택은 요소 중 가장 큰 값으로 숫자를 추정한다. np.argmax(predict(x_batch)[0]) 최종적으로 신경망이 추정한 값여기서는 0일 때의 추정치가 값이 제일크기 때문에 이미지 데이터를 0으로 추정했다고 본다. 여기까지가 신경망의 예측이다. 이제 우리는 손실함수로 이 신경망의 성능이 얼마나 나쁜지 확인할 것이다. 손실함수 먼저, 손실함수란 신경망 성능의 ‘나쁨’을 나타내는 지표이다. 성능의 나쁨을 나타내는 손실함수의 값이 가장 작은 곳에 가중치 최적값이 있다. 신경망은 손실함수가 최저가 되게 만드는 가중치 값을 찾는다. 손실함수로는 오차제곱합과 교차 엔트로피 오차가 있는데 가장 유명한 교차 엔트로피 오차만 살펴 보겠다. 교차 엔트로피 오차 교차엔트로피오차 식은 다음과 같다. 교차 엔트로피 오차 식 여기서 log는 자연로그이며 yk는 신경망이 학습을 통해 이미지를 추정한 값, tk는 앞서 살펴본 정답레이블이다. 예를 들면 다음과 같다. 123t = [0,0,1,0,0,0,0,0,0,0]y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]#참고 : t, y값은 예시를 위해 직접 작성한 값입니다. 변수 t는 정답레이블로, 손글씨 데이터의 실제 숫자가 “2”임을 의미한다. 이는 원-핫 인코딩 방식으로 정답에 해당하는 값만 1로 나타낸 것이다. 그리고 변수 y는 신경망이 학습을 통해 이미지를 추정한 값이다. 0.6이 제일 높으므로 신경망은 손글씨 이미지가 “2”라고 추정하고 있다. 교차 엔트로피 오차 식을 다시 살펴보면, 정답레이블(tk)을 곱하기 때문에 답이 아닌경우(=tk가 0인 경우) 는 값이 0이고 정답인 경우에만 값이 있으므로 실질적으로 정답일 때의 자연로그를 계산하는 식이 된다. 교차 엔트로피 오차 수식은 다음과 같이 구현한다. 1234567import numpy as npdef cross_entropy_error(y, t): delta = 1e-7 return -np.sum(t * np.log(y + delta)) cross_entropy_error(np.array(y), np.array(t)) 2가 정답일 때 신경망의 추정치는 0.6이며 이 때의 교차 엔트로피 오차는 약 0.51이다. 하나 더 살펴보자. 123y = [0.1, 0.05, 0.2, 0.1, 0.05, 0.1, 0.1, 0.1, 0.1, 0.1]cross_entropy_error(np.array(y), np.array(t)) 이번에는 2가 정답일 때 2에 대한 신경망의 추정치는 0.2이다. 이 때의 교차 엔트로피 오차는 1.61이다. 추정치가 정답과 멀어질수록 오차값이 큰 것을 알 수 있다. 여기까지 전체 데이터를 훈련데이터와 시험데이터로 분리하고 훈련데이터에서 배치 데이터 100개을 랜덤 추출했다. 그리고 이 배치 데이터를 예측하여 예측 값에 대한 손실함수를 구하는 것까지 살펴보았다. 다음 챕터에서 이 손실함수 예측값을 갖고 가중치 매개변수 최적값을 구하는 방법을 살펴볼 것이다. 그럼 안뇽~!","link":"/2020/04/11/book1-3/"}],"tags":[{"name":"딥러닝","slug":"딥러닝","link":"/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/"},{"name":"study","slug":"study","link":"/tags/study/"}],"categories":[{"name":"Book","slug":"Book","link":"/categories/Book/"},{"name":"밑바닥부터 시작하는 딥러닝","slug":"Book/밑바닥부터-시작하는-딥러닝","link":"/categories/Book/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D/"}]}