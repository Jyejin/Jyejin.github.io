<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>순전파를 사용하여 모델 학습하기 - 개발계발 블로그</title><meta description="순전파법을 사용하여 손글씨 추론 모델을 만들어보겠습니다. 순전파법의 기본 원리는 손실함수 값을 최소화 시키는 것입니다. 손실함수 값을 최소화 시키는 방법으로는 경사하강법(SGD)를 사용합니다. 순전파의 기본 설명은 다음 링크를 참고하세요.   신경망 학습하기-1 (손실함수, 교차엔트로피오차) CH5. 신경망 학습하기-2 (경사하강법)  먼저, 학습할 네트"><meta property="og:type" content="blog"><meta property="og:title" content="순전파를 사용하여 모델 학습하기"><meta property="og:url" content="https://jyejin.github.io/"><meta property="og:site_name" content="개발계발 블로그"><meta property="og:description" content="순전파법을 사용하여 손글씨 추론 모델을 만들어보겠습니다. 순전파법의 기본 원리는 손실함수 값을 최소화 시키는 것입니다. 손실함수 값을 최소화 시키는 방법으로는 경사하강법(SGD)를 사용합니다. 순전파의 기본 설명은 다음 링크를 참고하세요.   신경망 학습하기-1 (손실함수, 교차엔트로피오차) CH5. 신경망 학습하기-2 (경사하강법)  먼저, 학습할 네트"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2020-05-04T04:30:25.000Z"><meta property="article:modified_time" content="2021-05-16T06:17:07.476Z"><meta property="article:author" content="Yejin Jeong"><meta property="article:tag" content="딥러닝"><meta property="article:tag" content="project"><meta property="article:tag" content="모델학습"><meta property="article:tag" content="모델링"><meta property="article:tag" content="순전파"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://jyejin.github.io/gallery/project1-3-1.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jyejin.github.io/2020/05/04/project1-3/"},"headline":"개발계발 블로그","image":["https://jyejin.github.io/gallery/project1-3-1.png"],"datePublished":"2020-05-04T04:30:25.000Z","dateModified":"2021-05-16T06:17:07.476Z","author":{"@type":"Person","name":"Yejin Jeong"},"description":"순전파법을 사용하여 손글씨 추론 모델을 만들어보겠습니다. 순전파법의 기본 원리는 손실함수 값을 최소화 시키는 것입니다. 손실함수 값을 최소화 시키는 방법으로는 경사하강법(SGD)를 사용합니다. 순전파의 기본 설명은 다음 링크를 참고하세요.   신경망 학습하기-1 (손실함수, 교차엔트로피오차) CH5. 신경망 학습하기-2 (경사하강법)  먼저, 학습할 네트"}</script><link rel="canonical" href="https://jyejin.github.io/2020/05/04/project1-3/"><link rel="icon" href="/img/berry.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/vs.css"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">개발계발</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-04T04:30:25.000Z" title="2020-05-04T04:30:25.000Z">2020-05-04</time><span class="level-item"><a class="link-muted" href="/categories/Project/">Project</a><span> / </span><a class="link-muted" href="/categories/Project/DeepLearningFromForR/">DeepLearningFromForR</a></span><span class="level-item">7 minutes read (About 1073 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">순전파를 사용하여 모델 학습하기</h1><div class="content"><br/>
순전파법을 사용하여 손글씨 추론 모델을 만들어보겠습니다. 순전파법의 기본 원리는 손실함수 값을 최소화 시키는 것입니다. 손실함수 값을 최소화 시키는 방법으로는 경사하강법(SGD)를 사용합니다. 순전파의 기본 설명은 다음 링크를 참고하세요.

<ul>
<li><a href="https://jyejin.github.io/2020/04/11/book1-3/">신경망 학습하기-1 (손실함수, 교차엔트로피오차)</a></li>
<li><a href="https://jyejin.github.io/2020/04/11/book1-4/">CH5. 신경망 학습하기-2 (경사하강법)</a></li>
</ul>
<p>먼저, 학습할 네트워크를 만듭니다. W1,W2는 각 층별 가중치이며 b1,b2는 편향 값을 의미합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TwoLayerNet &lt;- <span class="keyword">function</span>(input_size, hidden_size, output_size, weight_init_std  =  <span class="number">0.01</span>) &#123;</span><br><span class="line">  W1 &lt;- weight_init_std * matrix(rnorm(n  =  input_size*hidden_size), nrow  =  input_size, ncol  =  hidden_size)</span><br><span class="line">  b1 &lt;- matrix(rep(<span class="number">0</span>,hidden_size), nrow = <span class="number">1</span>, ncol = hidden_size)</span><br><span class="line">  W2 &lt;- weight_init_std * matrix(rnorm(n  =  hidden_size*output_size), nrow  =  hidden_size, ncol  =  output_size)</span><br><span class="line">  b2 &lt;- matrix(rep(<span class="number">0</span>,output_size),nrow = <span class="number">1</span>, ncol = output_size)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> (list(W1 = W1, b1 = b1, W2 = W2, b2 = b2))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>TwoLayerNet</code> 네트워크는 아래와 같이 은닉층을 1개 갖습니다.</p>
<img src="/gallery/project1-3-1.png">

<p>입력층에서 <code>input_size</code> 개수만큼의 노드를 갖고 은닉층에서는 <code>hidden_size</code> 개수만큼의 노드, 출력층에서는 <code>output_size</code>만큼의 노드를 갖습니다. <code>W1</code>과 <code>b1</code>은 입력층에서 은닉층으로 갈 때의 가중치와 편향이며 <code>W2</code>와 <code>b2</code>는 은닉층에서 출력층으로 갈 때 사용하는 가중치와 편향입니다. 그리고 <code>weight_init_std</code>는 가중치 초기값이 큰 값이 되는 것을 방지하는 파라미터입니다.</p>
<p>다음으로, 데이터를 불러오고 트레이닝 셋과 테스트 셋으로 분류합니다. 데이터는 MNIST 라이브러리의 손글씨 이미지입니다. R에서는 dslabs를 임포트합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(dslabs)</span><br><span class="line"><span class="keyword">source</span>(<span class="string">"./functions.R"</span>)</span><br><span class="line"><span class="keyword">source</span>(<span class="string">"./utils.R"</span>)</span><br><span class="line"><span class="keyword">source</span>(<span class="string">"./model.R"</span>)</span><br><span class="line"></span><br><span class="line">init &lt;- <span class="keyword">function</span>()&#123;</span><br><span class="line">  mnist_data &lt;- get_data()</span><br><span class="line">  <span class="comment">#손글씨 데이터</span></span><br><span class="line">  x_train_normalize &lt;&lt;- mnist_data$x_train </span><br><span class="line">  x_test_normalize &lt;&lt;- mnist_data$x_test</span><br><span class="line">  <span class="comment">#정답 레이블</span></span><br><span class="line">  t_train_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_train,<span class="number">60000</span>, <span class="number">10</span>)</span><br><span class="line">  t_test_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_test,<span class="number">10000</span>, <span class="number">10</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>손실함수는 교차엔트로피오차 함수를 사용합니다. 교차엔트로피오차 함수는 아래와 같이 구현합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model.forward &lt;- <span class="keyword">function</span>(x)&#123;</span><br><span class="line">  z1 &lt;- sigmoid(sweep((x %*% network$W1),<span class="number">2</span>, network$b1,<span class="string">'+'</span>))</span><br><span class="line">  <span class="keyword">return</span>(softmax(sweep((z1 %*% network$W2),<span class="number">2</span>, network$b2,<span class="string">'+'</span>)))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cross_entropy_error &lt;- <span class="keyword">function</span>(y, t)&#123;</span><br><span class="line">    delta &lt;- <span class="number">1e-7</span></span><br><span class="line">    batchsize &lt;- dim(y)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span>(-sum(t * log(y + delta))/batchsize)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">loss &lt;-<span class="keyword">function</span>(x,t)&#123;</span><br><span class="line">  <span class="keyword">return</span>(cross_entropy_error(model.forward(x),t))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>기본 교차엔트로피 함수식에 <code>delta</code>값을 추가하였는데, 이는 log0이 되면 -Inf가 되는 문제를 방지하기 위해서 입니다.</p>
<p>다음으로 경사하강법은 손실함수 값을 최소화 시키기 위해 사용합니다. </p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">numerical_gradient_W &lt;- <span class="keyword">function</span>(f,x,t,weight)&#123;</span><br><span class="line">    h &lt;- <span class="number">1e-4</span></span><br><span class="line">    vec &lt;- matrix(<span class="number">0</span>, nrow = nrow(network[[weight]]) ,ncol = ncol(network[[weight]]))</span><br><span class="line">    <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:length(network[[weight]]))&#123;</span><br><span class="line">        origin &lt;-  network[[weight]][i]</span><br><span class="line">        network[[weight]][i] &lt;&lt;- (network[[weight]][i] + h)</span><br><span class="line">        fxh1 &lt;- f(x, t)</span><br><span class="line">        network[[weight]][i] &lt;&lt;- (network[[weight]][i] - (<span class="number">2</span>*h))</span><br><span class="line">        fxh2 &lt;- f(x, t)</span><br><span class="line">        vec[i] &lt;- (fxh1 - fxh2) / (<span class="number">2</span>*h)</span><br><span class="line">        network[[weight]][i] &lt;&lt;- origin</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>(vec)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">numerical_gradient &lt;- <span class="keyword">function</span>(f,x,t) &#123;</span><br><span class="line">  grads  &lt;- list(W1 = numerical_gradient_W(f,x,t,<span class="string">"W1"</span>), </span><br><span class="line">                 b1 = numerical_gradient_W(f,x,t,<span class="string">"b1"</span>), </span><br><span class="line">                 W2 = numerical_gradient_W(f,x,t,<span class="string">"W2"</span>), </span><br><span class="line">                 b2 = numerical_gradient_W(f,x,t,<span class="string">"b2"</span>))</span><br><span class="line">  <span class="keyword">return</span>(grads)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>마지막으로 학습시키는 함수입니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">train_model &lt;- <span class="keyword">function</span>(batch_size, iters_num, learning_rate, debug=<span class="literal">FALSE</span>)&#123;</span><br><span class="line">  <span class="comment">#seperate train, test data</span></span><br><span class="line">  init()</span><br><span class="line">  train_size &lt;- dim(x_train_normalize)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  iter_per_epoch &lt;- max(train_size / batch_size)</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:iters_num)&#123;</span><br><span class="line">    batch_mask &lt;- sample(train_size,batch_size)</span><br><span class="line">    x_batch &lt;- x_train_normalize[batch_mask,]</span><br><span class="line">    t_batch &lt;- t_train_onehotlabel[batch_mask,]</span><br><span class="line"></span><br><span class="line">    grad &lt;- numerical_gradient(loss, x_batch, t_batch)</span><br><span class="line">    network &lt;&lt;- sgd.update(network,grad,lr=learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(debug)&#123;</span><br><span class="line">        <span class="keyword">if</span>(i %% iter_per_epoch == <span class="number">0</span>)&#123;</span><br><span class="line">            train_acc &lt;- model.evaluate(model.forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">            test_acc &lt;- model.evaluate(model.forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">            print(c(train_acc, test_acc))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    train_accuracy = model.evaluate(model.forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">    test_accuracy = model.evaluate(model.forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">    <span class="keyword">return</span>(c(train_accuracy, test_accuracy))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>train_model()</code>함수 중간에 <code>sg.update()</code>함수는 경사하강법으로 변경된 가중치를 업데이트하는 역할을 합니다.<br>코드는 아래와 같습니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sgd.update &lt;- <span class="keyword">function</span>(network, grads, lr = <span class="number">0.01</span>)&#123;</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> names(network))&#123;network[[i]] &lt;- network[[i]] - (grads[[i]]*lr)&#125;</span><br><span class="line">  <span class="keyword">return</span>(network)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>이제 모든 준비를 마쳤습니다. 네트워크를 생성한 후 모델을 학습시켜봅니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">network &lt;&lt;- TwoLayerNet(input_size = <span class="number">784</span>, hidden_size = <span class="number">50</span>, output_size = <span class="number">10</span>)</span><br><span class="line">train_model(<span class="number">100</span>, <span class="number">10000</span>, <span class="number">0.1</span>, <span class="literal">TRUE</span>)</span><br></pre></td></tr></table></figure>



</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a><a class="link-muted mr-2" rel="tag" href="/tags/project/">project</a><a class="link-muted mr-2" rel="tag" href="/tags/%EB%AA%A8%EB%8D%B8%ED%95%99%EC%8A%B5/">모델학습</a><a class="link-muted mr-2" rel="tag" href="/tags/%EB%AA%A8%EB%8D%B8%EB%A7%81/">모델링</a><a class="link-muted mr-2" rel="tag" href="/tags/%EC%88%9C%EC%A0%84%ED%8C%8C/">순전파</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/05/12/project1-4/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">역전파를 사용하여 모델 학습하기</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/05/04/project2-1/"><span class="level-item">게시글</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://jyejin.github.io/2020/05/04/project1-3/';
            this.page.identifier = '2020/05/04/project1-3/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'jeanie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">개발계발</a><p class="size-small"><span>&copy; 2021 Yejin Jeong</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://jyejin.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: false,
                    fold: ''
                }
            }
        };</script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>