<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="yanm1ng&#39;s blog">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" type="image/ico" href="/gallery/berry.png"/>
  
  <title>
    
      순전파를 사용하여 모델 학습하기 | 개발계발 블로그
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/style.css">

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  
<meta name="generator" content="Hexo 4.2.0"></head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>개발계발 블로그</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>순전파를 사용하여 모델 학습하기</h2>
  <p class="post-date">2020-05-04</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><br/>
순전파법을 사용하여 손글씨 추론 모델을 만들어보겠습니다. 순전파법의 기본 원리는 손실함수 값을 최소화 시키는 것입니다. 손실함수 값을 최소화 시키는 방법으로는 경사하강법(SGD)를 사용합니다. 순전파의 기본 설명은 다음 링크를 참고하세요.

<ul>
<li><a href="https://jyejin.github.io/2020/04/11/book1-3/">신경망 학습하기-1 (손실함수, 교차엔트로피오차)</a></li>
<li><a href="https://jyejin.github.io/2020/04/11/book1-4/">CH5. 신경망 학습하기-2 (경사하강법)</a></li>
</ul>
<p>먼저, 학습할 네트워크를 만듭니다. W1,W2는 각 층별 가중치이며 b1,b2는 편향 값을 의미합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TwoLayerNet &lt;- <span class="keyword">function</span>(input_size, hidden_size, output_size, weight_init_std  =  <span class="number">0.01</span>) &#123;</span><br><span class="line">  W1 &lt;- weight_init_std * matrix(rnorm(n  =  input_size*hidden_size), nrow  =  input_size, ncol  =  hidden_size)</span><br><span class="line">  b1 &lt;- matrix(rep(<span class="number">0</span>,hidden_size), nrow = <span class="number">1</span>, ncol = hidden_size)</span><br><span class="line">  W2 &lt;- weight_init_std * matrix(rnorm(n  =  hidden_size*output_size), nrow  =  hidden_size, ncol  =  output_size)</span><br><span class="line">  b2 &lt;- matrix(rep(<span class="number">0</span>,output_size),nrow = <span class="number">1</span>, ncol = output_size)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> (list(W1 = W1, b1 = b1, W2 = W2, b2 = b2))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>TwoLayerNet</code> 네트워크는 아래와 같이 은닉층을 1개 갖습니다.</p>
<img src="/gallery/project1-3-1.png">

<p>입력층에서 <code>input_size</code> 개수만큼의 노드를 갖고 은닉층에서는 <code>hidden_size</code> 개수만큼의 노드, 출력층에서는 <code>output_size</code>만큼의 노드를 갖습니다. <code>W1</code>과 <code>b1</code>은 입력층에서 은닉층으로 갈 때의 가중치와 편향이며 <code>W2</code>와 <code>b2</code>는 은닉층에서 출력층으로 갈 때 사용하는 가중치와 편향입니다. 그리고 <code>weight_init_std</code>는 가중치 초기값이 큰 값이 되는 것을 방지하는 파라미터입니다.</p>
<p>다음으로, 데이터를 불러오고 트레이닝 셋과 테스트 셋으로 분류합니다. 데이터는 MNIST 라이브러리의 손글씨 이미지입니다. R에서는 dslabs를 임포트합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(dslabs)</span><br><span class="line"><span class="keyword">source</span>(<span class="string">"./functions.R"</span>)</span><br><span class="line"><span class="keyword">source</span>(<span class="string">"./utils.R"</span>)</span><br><span class="line"><span class="keyword">source</span>(<span class="string">"./model.R"</span>)</span><br><span class="line"></span><br><span class="line">init &lt;- <span class="keyword">function</span>()&#123;</span><br><span class="line">  mnist_data &lt;- get_data()</span><br><span class="line">  <span class="comment">#손글씨 데이터</span></span><br><span class="line">  x_train_normalize &lt;&lt;- mnist_data$x_train </span><br><span class="line">  x_test_normalize &lt;&lt;- mnist_data$x_test</span><br><span class="line">  <span class="comment">#정답 레이블</span></span><br><span class="line">  t_train_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_train,<span class="number">60000</span>, <span class="number">10</span>)</span><br><span class="line">  t_test_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_test,<span class="number">10000</span>, <span class="number">10</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>손실함수는 교차엔트로피오차 함수를 사용합니다. 교차엔트로피오차 함수는 아래와 같이 구현합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model.forward &lt;- <span class="keyword">function</span>(x)&#123;</span><br><span class="line">  z1 &lt;- sigmoid(sweep((x %*% network$W1),<span class="number">2</span>, network$b1,<span class="string">'+'</span>))</span><br><span class="line">  <span class="keyword">return</span>(softmax(sweep((z1 %*% network$W2),<span class="number">2</span>, network$b2,<span class="string">'+'</span>)))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cross_entropy_error &lt;- <span class="keyword">function</span>(y, t)&#123;</span><br><span class="line">    delta &lt;- <span class="number">1e-7</span></span><br><span class="line">    batchsize &lt;- dim(y)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span>(-sum(t * log(y + delta))/batchsize)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">loss &lt;-<span class="keyword">function</span>(x,t)&#123;</span><br><span class="line">  <span class="keyword">return</span>(cross_entropy_error(model.forward(x),t))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>기본 교차엔트로피 함수식에 <code>delta</code>값을 추가하였는데, 이는 log0이 되면 -Inf가 되는 문제를 방지하기 위해서 입니다.</p>
<p>다음으로 경사하강법은 손실함수 값을 최소화 시키기 위해 사용합니다. </p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">numerical_gradient_W &lt;- <span class="keyword">function</span>(f,x,t,weight)&#123;</span><br><span class="line">    h &lt;- <span class="number">1e-4</span></span><br><span class="line">    vec &lt;- matrix(<span class="number">0</span>, nrow = nrow(network[[weight]]) ,ncol = ncol(network[[weight]]))</span><br><span class="line">    <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:length(network[[weight]]))&#123;</span><br><span class="line">        origin &lt;-  network[[weight]][i]</span><br><span class="line">        network[[weight]][i] &lt;&lt;- (network[[weight]][i] + h)</span><br><span class="line">        fxh1 &lt;- f(x, t)</span><br><span class="line">        network[[weight]][i] &lt;&lt;- (network[[weight]][i] - (<span class="number">2</span>*h))</span><br><span class="line">        fxh2 &lt;- f(x, t)</span><br><span class="line">        vec[i] &lt;- (fxh1 - fxh2) / (<span class="number">2</span>*h)</span><br><span class="line">        network[[weight]][i] &lt;&lt;- origin</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>(vec)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">numerical_gradient &lt;- <span class="keyword">function</span>(f,x,t) &#123;</span><br><span class="line">  grads  &lt;- list(W1 = numerical_gradient_W(f,x,t,<span class="string">"W1"</span>), </span><br><span class="line">                 b1 = numerical_gradient_W(f,x,t,<span class="string">"b1"</span>), </span><br><span class="line">                 W2 = numerical_gradient_W(f,x,t,<span class="string">"W2"</span>), </span><br><span class="line">                 b2 = numerical_gradient_W(f,x,t,<span class="string">"b2"</span>))</span><br><span class="line">  <span class="keyword">return</span>(grads)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>마지막으로 학습시키는 함수입니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">train_model &lt;- <span class="keyword">function</span>(batch_size, iters_num, learning_rate, debug=<span class="literal">FALSE</span>)&#123;</span><br><span class="line">  <span class="comment">#seperate train, test data</span></span><br><span class="line">  init()</span><br><span class="line">  train_size &lt;- dim(x_train_normalize)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  iter_per_epoch &lt;- max(train_size / batch_size)</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:iters_num)&#123;</span><br><span class="line">    batch_mask &lt;- sample(train_size,batch_size)</span><br><span class="line">    x_batch &lt;- x_train_normalize[batch_mask,]</span><br><span class="line">    t_batch &lt;- t_train_onehotlabel[batch_mask,]</span><br><span class="line"></span><br><span class="line">    grad &lt;- numerical_gradient(loss, x_batch, t_batch)</span><br><span class="line">    network &lt;&lt;- sgd.update(network,grad,lr=learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(debug)&#123;</span><br><span class="line">        <span class="keyword">if</span>(i %% iter_per_epoch == <span class="number">0</span>)&#123;</span><br><span class="line">            train_acc &lt;- model.evaluate(model.forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">            test_acc &lt;- model.evaluate(model.forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">            print(c(train_acc, test_acc))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    train_accuracy = model.evaluate(model.forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">    test_accuracy = model.evaluate(model.forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">    <span class="keyword">return</span>(c(train_accuracy, test_accuracy))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>train_model()</code>함수 중간에 <code>sg.update()</code>함수는 경사하강법으로 변경된 가중치를 업데이트하는 역할을 합니다.<br>코드는 아래와 같습니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sgd.update &lt;- <span class="keyword">function</span>(network, grads, lr = <span class="number">0.01</span>)&#123;</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> names(network))&#123;network[[i]] &lt;- network[[i]] - (grads[[i]]*lr)&#125;</span><br><span class="line">  <span class="keyword">return</span>(network)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>이제 모든 준비를 마쳤습니다. 네트워크를 생성한 후 모델을 학습시켜봅니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">network &lt;&lt;- TwoLayerNet(input_size = <span class="number">784</span>, hidden_size = <span class="number">50</span>, output_size = <span class="number">10</span>)</span><br><span class="line">train_model(<span class="number">100</span>, <span class="number">10000</span>, <span class="number">0.1</span>, <span class="literal">TRUE</span>)</span><br></pre></td></tr></table></figure>



</section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#딥러닝" >
    <span class="tag-code">딥러닝</span>
  </a>

  <a href="/tags#project" >
    <span class="tag-code">project</span>
  </a>

  <a href="/tags#순전파" >
    <span class="tag-code">순전파</span>
  </a>

  <a href="/tags#모델학습" >
    <span class="tag-code">모델학습</span>
  </a>

  <a href="/tags#모델링" >
    <span class="tag-code">모델링</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2020/05/04/project2-1/">
        <span class="nav-arrow">← </span>
        
          게시글
        
      </a>
    
    
      <a class="nav-right" href="/2020/05/12/project1-4/">
        
          역전파를 사용하여 모델 학습하기
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
    
    <!-- 打赏 END -->
    <!-- 二维码 START -->
    
    <!-- 二维码 END -->
    
      <!-- No Comment -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="nav">none</ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'https://jyejin.github.io/2020/05/04/project1-3/';
    var banner = ''
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

    // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()

        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })
  })();
</script>







    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2020 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a href="https://github.com/yanm1ng" target="_blank" rel="noopener">yanm1ng</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->


<script src="/js/script.js"></script>

  </body>
</html>