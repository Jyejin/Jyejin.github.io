<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>역전파를 사용하여 모델 학습하기 - 개발계발 블로그</title><meta description="오차역전파를 사용한 학습도 손실함수를 최소화하는 가중치를 찾는 것을 목표로합니다. 다만, 역전파는 가중치를 구함에 있어 연쇄법칙에 기반한 국소적 미분을 활용합니다. 순전파와 비교했을 때 훨씬 빠른 시간 안에 효울적으로 계산한다는 장점이 있습니다. 이번에는 역전파법을 사용하여 모델 학습을 진행해 보겠습니다. 먼저, 라이브러리와 공통함수를 읽어옵니다. 12"><meta property="og:type" content="blog"><meta property="og:title" content="역전파를 사용하여 모델 학습하기"><meta property="og:url" content="https://jyejin.github.io/"><meta property="og:site_name" content="개발계발 블로그"><meta property="og:description" content="오차역전파를 사용한 학습도 손실함수를 최소화하는 가중치를 찾는 것을 목표로합니다. 다만, 역전파는 가중치를 구함에 있어 연쇄법칙에 기반한 국소적 미분을 활용합니다. 순전파와 비교했을 때 훨씬 빠른 시간 안에 효울적으로 계산한다는 장점이 있습니다. 이번에는 역전파법을 사용하여 모델 학습을 진행해 보겠습니다. 먼저, 라이브러리와 공통함수를 읽어옵니다. 12"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2020-05-12T09:28:10.000Z"><meta property="article:modified_time" content="2021-05-16T06:17:11.126Z"><meta property="article:author" content="Yejin Jeong"><meta property="article:tag" content="딥러닝"><meta property="article:tag" content="project"><meta property="article:tag" content="역전파"><meta property="article:tag" content="모델학습"><meta property="article:tag" content="모델링"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://jyejin.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jyejin.github.io/2020/05/12/project1-4/"},"headline":"개발계발 블로그","image":["https://jyejin.github.io/img/og_image.png"],"datePublished":"2020-05-12T09:28:10.000Z","dateModified":"2021-05-16T06:17:11.126Z","author":{"@type":"Person","name":"Yejin Jeong"},"description":"오차역전파를 사용한 학습도 손실함수를 최소화하는 가중치를 찾는 것을 목표로합니다. 다만, 역전파는 가중치를 구함에 있어 연쇄법칙에 기반한 국소적 미분을 활용합니다. 순전파와 비교했을 때 훨씬 빠른 시간 안에 효울적으로 계산한다는 장점이 있습니다. 이번에는 역전파법을 사용하여 모델 학습을 진행해 보겠습니다. 먼저, 라이브러리와 공통함수를 읽어옵니다. 12"}</script><link rel="canonical" href="https://jyejin.github.io/2020/05/12/project1-4/"><link rel="icon" href="/img/berry.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">개발계발</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-12T09:28:10.000Z" title="2020-05-12T09:28:10.000Z">2020-05-12</time><span class="level-item"><a class="link-muted" href="/categories/Project/">Project</a><span> / </span><a class="link-muted" href="/categories/Project/DeepLearningFromForR/">DeepLearningFromForR</a></span><span class="level-item">7 minutes read (About 1107 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">역전파를 사용하여 모델 학습하기</h1><div class="content"><br/>

<p>오차역전파를 사용한 학습도 손실함수를 최소화하는 가중치를 찾는 것을 목표로합니다. 다만, 역전파는 가중치를 구함에 있어 연쇄법칙에 기반한 국소적 미분을 활용합니다. 순전파와 비교했을 때 훨씬 빠른 시간 안에 효울적으로 계산한다는 장점이 있습니다. 이번에는 역전파법을 사용하여 모델 학습을 진행해 보겠습니다.</p>
<p>먼저, 라이브러리와 공통함수를 읽어옵니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#install.packages("dslabs")</span></span><br><span class="line">    <span class="keyword">library</span>(dslabs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">source</span>(<span class="string">"./functions.R"</span>)</span><br><span class="line">    <span class="keyword">source</span>(<span class="string">"./utils.R"</span>)</span><br><span class="line">    <span class="keyword">source</span>(<span class="string">"./model.R"</span>)</span><br></pre></td></tr></table></figure>

<p>1개의 은닉층을 갖는 네트워크를 생성합니다. 네트워크는 순전파와 동일합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TwoLayerNet &lt;- <span class="keyword">function</span>(input_size, hidden_size, output_size, weight_init_std  =  <span class="number">0.01</span>) &#123;</span><br><span class="line">  W1 &lt;- weight_init_std * matrix(rnorm(n  =  input_size*hidden_size), nrow  =  input_size, ncol  =  hidden_size)</span><br><span class="line">  b1 &lt;- matrix(rep(<span class="number">0</span>,hidden_size), nrow = <span class="number">1</span>, ncol = hidden_size)</span><br><span class="line">  W2 &lt;- weight_init_std * matrix(rnorm(n  =  hidden_size*output_size), nrow  =  hidden_size, ncol  =  output_size)</span><br><span class="line">  b2 &lt;- matrix(rep(<span class="number">0</span>,output_size),nrow = <span class="number">1</span>, ncol = output_size)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> (list(W1 = W1, b1 = b1, W2 = W2, b2 = b2))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>데이터를 불러와 트레이닝셋과 테스트셋으로 분리하는 <code>init()</code>함수를 생성합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">init &lt;- <span class="keyword">function</span>()&#123;</span><br><span class="line">  mnist_data &lt;- get_data()</span><br><span class="line">  <span class="comment">#손글씨 데이터</span></span><br><span class="line">  x_train_normalize &lt;&lt;- mnist_data$x_train </span><br><span class="line">  x_test_normalize &lt;&lt;- mnist_data$x_test</span><br><span class="line">  <span class="comment">#정답 레이블</span></span><br><span class="line">  t_train_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_train,<span class="number">60000</span>, <span class="number">10</span>)</span><br><span class="line">  t_test_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_test,<span class="number">10000</span>, <span class="number">10</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>앞서 역전파에서는 국소적 미분을 사용한다고 했습니다. 순전파와 반대방향으로 국소적 미분을 곱하여 이전 노드들에 값을 전달하는 것인데, 국소적 미분은 순전파 때의 미분을 구한다는 뜻입니다. 다시 말해, 순전파 때의 미분 값을 구해 다음 노드에 전달하는 함수가 필요합니다.<br>다음 코드는 순전파 때와 마찬가지로 입력신호와 가중치를 계산하고 Relu함수를 거쳐 다음 노드로 전달합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">forward &lt;- <span class="keyword">function</span>(x)&#123;</span><br><span class="line">  Affine_1 &lt;- Affine.forward(network$W1, network$b1, x)</span><br><span class="line">  Relu_1 &lt;- Relu.forward(Affine_1$out)</span><br><span class="line">  Affine_2 &lt;- Affine.forward(network$W2, network$b2, Relu_1$out)</span><br><span class="line">  <span class="keyword">return</span>(list(x = Affine_2$out, Affine_1.forward = Affine_1, Affine_2.forward = Affine_2, Relu_1.forward = Relu_1))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>역전파도 마찬가지로 손실함수를 계산합니다. </p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss &lt;- <span class="keyword">function</span>(model.forward, x, t)&#123;</span><br><span class="line">  temp &lt;- model.forward(x)</span><br><span class="line">  y &lt;- temp$x</span><br><span class="line">  last_layer.forward &lt;- SoftmaxWithLoss.forward(y, t)</span><br><span class="line">  <span class="keyword">return</span>(list(loss = last_layer.forward$loss, softmax = last_layer.forward, predict =  temp))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>순전파와 달리 마지막 노드에서부터 거꾸로 계산해 기울기를 구합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">gradient &lt;- <span class="keyword">function</span>(model.forward, x, t) &#123;</span><br><span class="line">  <span class="comment"># 순전파</span></span><br><span class="line">  temp &lt;- loss(model.forward, x, t)</span><br><span class="line">  <span class="comment"># 역전파</span></span><br><span class="line">  dout &lt;- <span class="number">1</span></span><br><span class="line">  last.backward &lt;- SoftmaxWithLoss.backward(temp$softmax, dout)</span><br><span class="line">  Affine_2.backward &lt;- Affine.backward(temp$predict$Affine_2.forward, dout  =  last.backward$dx)</span><br><span class="line">  Relu_1.backward &lt;- Relu.backward(temp$predict$Relu_1.forward, dout  =  Affine_2.backward$dx)</span><br><span class="line">  Affine_1.backward &lt;- Affine.backward(temp$predict$Affine_1.forward, dout  =  Relu_1.backward$dx)</span><br><span class="line">  grads  &lt;- list(W1  =  Affine_1.backward$dW, b1  =  Affine_1.backward$db, W2  =  Affine_2.backward$dW, b2  =  Affine_2.backward$db)</span><br><span class="line">  <span class="keyword">return</span>(grads)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>다음은 학습을 실제로 진행하는 코드입니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">train_model &lt;- <span class="keyword">function</span>(batch_size, iters_num, learning_rate, debug=<span class="literal">FALSE</span>)&#123;</span><br><span class="line">  <span class="comment">#seperate train, test data</span></span><br><span class="line">  init()</span><br><span class="line">  train_size &lt;- dim(x_train_normalize)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  iter_per_epoch &lt;- max(train_size / batch_size)</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:iters_num)&#123;</span><br><span class="line">      batch_mask &lt;- sample(train_size ,batch_size)</span><br><span class="line">      x_batch &lt;- x_train_normalize[batch_mask,]</span><br><span class="line">      t_batch &lt;- t_train_onehotlabel[batch_mask,]</span><br><span class="line"></span><br><span class="line">      grad &lt;- gradient(model.forward=forward, x_batch, t_batch)</span><br><span class="line">      <span class="comment">#update weights and biases using SGD</span></span><br><span class="line">      network &lt;&lt;- sgd.update(network,grad,lr=learning_rate)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span>(debug == <span class="literal">TRUE</span>)&#123;</span><br><span class="line">          <span class="keyword">if</span>(i %% iter_per_epoch == <span class="number">0</span>)&#123;</span><br><span class="line">              train_acc &lt;- model.evaluate(forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">              test_acc &lt;- model.evaluate(forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">              print(c(train_acc, test_acc))</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  train_accuracy = model.evaluate(forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">  test_accuracy = model.evaluate(forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">  <span class="keyword">return</span>(c(train_accuracy, test_accuracy))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>train_model()</code>함수 중간에 <code>sg.update()</code>함수는 경사하강법으로 변경된 가중치를 업데이트하는 역할을 합니다.<br>코드는 아래와 같습니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sgd.update &lt;- <span class="keyword">function</span>(network, grads, lr = <span class="number">0.01</span>)&#123;</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> names(network))&#123;network[[i]] &lt;- network[[i]] - (grads[[i]]*lr)&#125;</span><br><span class="line">  <span class="keyword">return</span>(network)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>이제 모든 준비를 마쳤습니다. 네트워크를 생성한 후 모델을 학습시켜봅니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">network &lt;&lt;- TwoLayerNet(input_size = <span class="number">784</span>, hidden_size = <span class="number">50</span>, output_size = <span class="number">10</span>)</span><br><span class="line">train_model(<span class="number">100</span>, <span class="number">10000</span>, <span class="number">0.1</span>, <span class="literal">TRUE</span>)</span><br></pre></td></tr></table></figure>

<p>위 코드를 실행시키고 3분 정도 지나면 아래와 같은 출력화면이 나올 것입니다. 한 행의 첫 번째 숫자는 훈련데이터 셋에 대한 정확도, 두 번째 숫자는 테스트 셋에 대한 정확도를 나타냅니다. 그리고 하나의 행은 1에폭(epoch)을 의미합니다. 에폭을 진행할수록 정확도가 높아지는 것을 확인할 수 있습니다!</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span>] <span class="number">0.9048</span> <span class="number">0.9059</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9228</span> <span class="number">0.9247</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9355833</span> <span class="number">0.9343000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9436167</span> <span class="number">0.9416000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9496167</span> <span class="number">0.9470000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9563167</span> <span class="number">0.9519000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9602167</span> <span class="number">0.9555000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9629167</span> <span class="number">0.9558000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9664833</span> <span class="number">0.9603000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9680333</span> <span class="number">0.9619000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9711167</span> <span class="number">0.9635000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.97315</span> <span class="number">0.96520</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.97445</span> <span class="number">0.96570</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9754167</span> <span class="number">0.9659000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9771167</span> <span class="number">0.9698000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9779</span> <span class="number">0.9679</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9776833</span> <span class="number">0.9680000</span></span><br></pre></td></tr></table></figure>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a><a class="link-muted mr-2" rel="tag" href="/tags/project/">project</a><a class="link-muted mr-2" rel="tag" href="/tags/%EC%97%AD%EC%A0%84%ED%8C%8C/">역전파</a><a class="link-muted mr-2" rel="tag" href="/tags/%EB%AA%A8%EB%8D%B8%ED%95%99%EC%8A%B5/">모델학습</a><a class="link-muted mr-2" rel="tag" href="/tags/%EB%AA%A8%EB%8D%B8%EB%A7%81/">모델링</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/05/22/book3-1/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">헤더와 바디</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/05/04/project1-3/"><span class="level-item">순전파를 사용하여 모델 학습하기</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://jyejin.github.io/2020/05/12/project1-4/';
            this.page.identifier = '2020/05/12/project1-4/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'jeanie' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">개발계발</a><p class="size-small"><span>&copy; 2021 Yejin Jeong</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://jyejin.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: false,
                    fold: ''
                }
            }
        };</script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>